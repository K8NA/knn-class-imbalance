{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "PRACTICAL ASSIGNMENT ML I: \n",
    "Altering the KNN algorithm by assigning weights to datapoints in order to improve the F1-score metric of binary classification targets in heavily imbalanced numeric datasets."
   ],
   "id": "bf5901a7a62c5853"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T23:30:58.669694Z",
     "start_time": "2024-05-19T23:30:53.808740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openml\n",
    "import warnings\n",
    "\n",
    "from mla.knn import KNNClassifier\n",
    "from mla.metrics import accuracy\n",
    "\n",
    "from wei import KNNClassifier as clas\n",
    "from wei import KNNRegressor as res\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import scikit_posthocs as sp\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "e4b53214eaef7184",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autograd'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mknn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KNNClassifier\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_val_score\n",
      "File \u001B[1;32m~\\Desktop\\CC2008AC\\PLs\\knn-class-imbalance\\mla\\metrics\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# coding:utf-8\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "File \u001B[1;32m~\\Desktop\\CC2008AC\\PLs\\knn-class-imbalance\\mla\\metrics\\metrics.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# coding:utf-8\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mautograd\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      4\u001B[0m EPS \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1e-15\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21munhot\u001B[39m(function):\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'autograd'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Suprimir avisos futuros \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "id": "4b77c1d022d1c2a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Carregar dataset\n",
    "dataset = openml.datasets.get_dataset(1464, download_data=True)\n",
    "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)"
   ],
   "id": "3093f51278bfbc7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Dividir em sets de treino e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=222)"
   ],
   "id": "7c5cc125805a5119",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Inicializar o classificador KNN \n",
    "knn = KNNClassifier(k=5)"
   ],
   "id": "edd3ab96040baf52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Treino\n",
    "knn.fit(X_train, y_train)"
   ],
   "id": "87cd1fc68d73d83d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Predição\n",
    "y_pred = knn.predict(X_test)"
   ],
   "id": "af3985b4baeefab8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_benchmark(models, model_names, benchmark=\"OpenML-CC18\"):\n",
    "    results = pd.DataFrame(columns=[\"dataset\", \"model\", \"score\"]) # create dataframe for results\n",
    "    benchmark_suite = openml.study.get_suite(benchmark) # obtain the benchmark suite\n",
    "\n",
    "    # datasets IDs \n",
    "        # 40983\n",
    "        # 40994\n",
    "        # 1464\n",
    "        # 1487\n",
    "        # 1494\n",
    "        # 1489\n",
    "        # 1068\n",
    "        # 1067\n",
    "        # 1063\n",
    "        # 1053\n",
    "        # 1050\n",
    "        # 1049\n",
    "    subset_benchmark_suite = benchmark_suite.tasks[0:10] \n",
    "\n",
    "    #for task_id in benchmark_suite.tasks:  # iterate over all tasks\n",
    "    for task_id in subset_benchmark_suite: # iterate over subset tasks\n",
    "        task = openml.tasks.get_task(task_id)  # download the OpenML task\n",
    "        features, targets = task.get_X_and_y()  # get the data\n",
    "        for model in range(len(models)): # iterate over all models\n",
    "            score = np.mean(cross_val_score(models[model], features, targets, cv=10, scoring=\"roc_auc_ovr\")) \n",
    "            if model_names:\n",
    "                results = pd.concat([results, pd.DataFrame([[task_id, model_names[model], score]], columns=results.columns)], ignore_index=True)\n",
    "            else:\n",
    "                results = pd.concat([results, pd.DataFrame([[task_id, str(models[model]), score]], columns=results.columns)], ignore_index=True) \n",
    "    results.to_csv(\"results.csv\", index=False)\n",
    "    "
   ],
   "id": "c5f263284e7c9e73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "KNN = make_pipeline(SimpleImputer(strategy='constant'),StandardScaler(),KNeighborsClassifier())\n",
    "KNN2 = make_pipeline(SimpleImputer(strategy='constant'), StandardScaler(), clas())\n",
    "models = [KNN, KNN2]\n",
    "model_names = [\"KNN\",\"KNN2\"]\n",
    "run_benchmark(models=models, model_names=model_names)"
   ],
   "id": "d409cdd1b7b6449e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = pd.read_csv(\"results.csv\")\n",
    "avg_rank = results.groupby('dataset').score.rank(pct=True).groupby(results.model).mean()\n",
    "avg_rank"
   ],
   "id": "4cc41617ce10c5ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "55d697cef2f64fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ss.friedmanchisquare(results.loc[results[\"model\"]==\"KNN\",:][[\"score\"]], results.loc[results[\"model\"]==\"KNN2\",:][[\"score\"]])",
   "id": "3ad2faa3916f22bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_results = sp.posthoc_conover_friedman(\n",
    "    results,\n",
    "    melted=True,\n",
    "    block_col='dataset',\n",
    "    group_col='model',\n",
    "    y_col='score',\n",
    ")\n",
    "sp.sign_plot(test_results)"
   ],
   "id": "1f73c12b5eacff7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Calcular a accuracy\n",
    "acc = accuracy(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ],
   "id": "8ef86eb56eb2bdfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_cv(results_cv,metric='Accuracy'):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(results_cv)\n",
    "    ax.set_xticklabels(results_cv.columns)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title('Cross-validation results for KNN and KNN2 in a dataset')\n",
    "    plt.show()"
   ],
   "id": "c28956b2b64345d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular o F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 Score: \", f1)"
   ],
   "id": "62f93a947a9bc092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calcular e imprimir a precisão (precision), recall e F1 score para cada classe\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1_per_class = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"Precision per class: \", precision)\n",
    "print(\"Recall per class: \", recall)\n",
    "print(\"F1 Score per class: \", f1_per_class)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
