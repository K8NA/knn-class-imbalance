{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "PRACTICAL ASSIGNMENT ML I: Altering the KNN algorithm by assigning weights to datapoints in order to improve the F1-score metric of binary classification targets in heavily imbalanced numeric datasets.",
   "id": "43f47fd0f615402b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T13:26:44.649843Z",
     "start_time": "2024-05-27T13:26:40.769679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openml\n",
    "import warnings\n",
    "\n",
    "from mla.knn import KNNClassifier as mlaKNNClassifier\n",
    "from mla.metrics import accuracy\n",
    "\n",
    "from wei import KNNClassifier as weiKNNClassifier\n",
    "from wei import KNNRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "7ecf5b07e13b6efc",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wei'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mknn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KNNClassifier \u001B[38;5;28;01mas\u001B[39;00m mlaKNNClassifier\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmla\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwei\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KNNClassifier \u001B[38;5;28;01mas\u001B[39;00m weiKNNClassifier\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwei\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KNNRegressor\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split, cross_val_score\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'wei'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "86f7983126cc8df4",
   "metadata": {},
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a1dcba3a2749403",
   "metadata": {},
   "source": [
    "def run_benchmark():\n",
    "    results = pd.DataFrame(columns=[\"dataset\", \"model\", \"score\"]) \n",
    "    \n",
    "    set_ids = [40983, 1464, 1487, 1494, 1489, 1068, 1067, 1063, 1050, 1049]\n",
    "        \n",
    "    KNN = make_pipeline(SimpleImputer(strategy='constant'), StandardScaler(), mlaKNNClassifier(k=5))\n",
    "    KNN2 = make_pipeline(SimpleImputer(strategy='constant'), StandardScaler(), weiKNNClassifier(k=5))\n",
    "    models = [KNN, KNN2]\n",
    "    model_names = [\"KNN\", \"KNN2\"]\n",
    "\n",
    "    # Iterate over the subset of tasks\n",
    "    for set_id in set_ids:\n",
    "        dataset = openml.datasets.get_dataset(set_id, download_data=True)  \n",
    "        X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
    "        train_models(X, y)\n",
    "        for model_idx in range(len(models)):\n",
    "            model = models[model_idx]\n",
    "            score = np.mean(cross_val_score(models[model_idx], X, y, cv=10, scoring=\"roc_auc_ovr\"))\n",
    "            model_name = model_names[model_idx] if model_names else str(model)\n",
    "            results = pd.concat([results, pd.DataFrame([[set_id, model_name, score]], columns=results.columns)],\n",
    "                                ignore_index=True)\n",
    "    results.to_csv(\"results.csv\", index=False)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "knn = mlaKNNClassifier(k=5)\n",
    "knn2 = mlaKNNClassifier(k=5)"
   ],
   "id": "d602cc69496b74f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_models(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=222)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    knn2.fit(X_train, y_train)\n",
    "    y_pred2 = knn2.predict(X_test)\n",
    "    acc = accuracy(y_test, y_pred)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"F1 Score: \", f1)\n",
    "    precision = precision_score(y_test, y_pred, average=None)\n",
    "    recall = recall_score(y_test, y_pred, average=None)\n",
    "    f1_per_class = 2 * (precision * recall) / (precision + recall)\n",
    "    print(\"Precision per class: \", precision)\n",
    "    print(\"Recall per class: \", recall)\n",
    "    print(\"F1 Score per class: \", f1_per_class)"
   ],
   "id": "baaa059145136e83",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd8253ee94fee8cf",
   "metadata": {},
   "source": "run_benchmark()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a7c5652337ab8b8",
   "metadata": {},
   "source": [
    "# Load results and calculate average rank\n",
    "results = pd.read_csv(\"results.csv\")\n",
    "avg_rank = results.groupby('dataset').score.rank(pct=True).groupby(results.model).mean()\n",
    "avg_rank"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "eab1221684098080",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "47767f49f1b69ed4",
   "metadata": {},
   "source": [
    "# Plot cross-validation results\n",
    "def plot_cv(results_cv, metric='Accuracy'):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(results_cv)\n",
    "    ax.set_xticklabels(results_cv.columns)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title('Cross-validation results for KNN and KNN2 in a dataset')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_cv(results, metric='Accuracy')",
   "id": "86290bdb47f26264",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = {\n",
    "    'Dataset': ['40983', '1464', '1487', '1494', '1489', '1068', '1067', '1063', '1050', '1049'],\n",
    "    'KNN_Accuracy': [0.9762396694214877, 0.7866666666666666, 0.9349112426035503, 0.8293838862559242, 0.8649398704902868, 0.9414414414414415, 0.8815165876777251, 0.8, 0.8913738019169329, 0.863013698630137],\n",
    "    'KNN2_Accuracy': [0.9793388429752066, 0.7533333333333333, 0.9349112426035503, 0.8483412322274881, 0.8899167437557817, 0.9369369369369369, 0.8507109004739337, 0.780952380952381, 0.8722044728434505, 0.8595890410958904],\n",
    "    'KNN_F1': [0.9730950356532211, 0.765079365079365, 0.9180883022303141, 0.8310351738368302, 0.8626940198962983, 0.9311365855019106, 0.8656050718344458, 0.7851273238556475, 0.8658742621974334, 0.8292356709602671],\n",
    "    'KNN2_F1': [0.9770480647859083, 0.7446382189239332, 0.920465202997901, 0.8493565337303616, 0.8886373268973798, 0.9279236783953765, 0.8317656323221783, 0.7584217687074829, 0.861973166771247, 0.8309572511828757]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ],
   "id": "c12bab6d51ef1572",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot accuracy for KNN and KNN2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Dataset'], df['KNN_Accuracy'], marker='o', label='KNN Accuracy')\n",
    "plt.plot(df['Dataset'], df['KNN2_Accuracy'], marker='o', label='KNN2 Accuracy')\n",
    "plt.xlabel('Dataset ID')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of KNN and KNN2 across Datasets')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "f2832285d33baa52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot F1 scores for KNN and KNN2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Dataset'], df['KNN_F1'], marker='o', label='KNN F1 Score')\n",
    "plt.plot(df['Dataset'], df['KNN2_F1'], marker='o', label='KNN2 F1 Score')\n",
    "plt.xlabel('Dataset ID')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Scores of KNN and KNN2 across Datasets')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "e77f3681e9c354f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "datasets = ['40983', '1464', '1487', '1494', '1489', '1068', '1067', '1063', '1050', '1049']\n",
    "knn_precision_per_class = [\n",
    "    [0.97547974, 1.0],\n",
    "    [0.83333333, 0.44444444],\n",
    "    [0.94578313, 0.33333333],\n",
    "    [0.88888889, 0.72368421],\n",
    "    [0.88861076, 0.79787234],\n",
    "    [0.9537037, 0.5],\n",
    "    [0.90609137, 0.53571429],\n",
    "    [0.84444444, 0.53333333],\n",
    "    [0.91447368, 0.11111111],\n",
    "    [0.88256228, 0.36363636]\n",
    "]\n",
    "\n",
    "knn_recall_per_class = [\n",
    "    [1.0, 0.56603774],\n",
    "    [0.91666667, 0.26666667],\n",
    "    [0.98742138, 0.1],\n",
    "    [0.85106383, 0.78571429],\n",
    "    [0.92568449, 0.71656051],\n",
    "    [0.98564593, 0.23076923],\n",
    "    [0.96486486, 0.28846154],\n",
    "    [0.91566265, 0.36363636],\n",
    "    [0.97202797, 0.03703704],\n",
    "    [0.97254902, 0.10810811]\n",
    "]\n",
    "\n",
    "knn2_precision_per_class = [\n",
    "    [0.97860963, 1.0],\n",
    "    [0.832, 0.36],\n",
    "    [0.94758065, 0.36363636],\n",
    "    [0.89781022, 0.75675676],\n",
    "    [0.91012658, 0.83505155],\n",
    "    [0.95348837, 0.42857143],\n",
    "    [0.89058524, 0.31034483],\n",
    "    [0.82608696, 0.46153846],\n",
    "    [0.91836735, 0.15789474],\n",
    "    [0.88489209, 0.35714286]\n",
    "]\n",
    "\n",
    "knn2_recall_per_class = [\n",
    "    [1.0, 0.62264151],\n",
    "    [0.86666667, 0.3],\n",
    "    [0.98532495, 0.13333333],\n",
    "    [0.87234043, 0.8],\n",
    "    [0.93741851, 0.77388535],\n",
    "    [0.98086124, 0.23076923],\n",
    "    [0.94594595, 0.17307692],\n",
    "    [0.91566265, 0.27272727],\n",
    "    [0.94405594, 0.11111111],\n",
    "    [0.96470588, 0.13513514]\n",
    "]"
   ],
   "id": "f9d84950d35ccbf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_precision_recall(dataset_index):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "    \n",
    "    # Precision plot\n",
    "    axes[0].bar(['Class 0', 'Class 1'], knn_precision_per_class[dataset_index], label='KNN Precision', alpha=0.6)\n",
    "    axes[0].bar(['Class 0', 'Class 1'], knn2_precision_per_class[dataset_index], label='KNN2 Precision', alpha=0.6)\n",
    "    axes[0].set_title(f'Precision for Dataset {datasets[dataset_index]}')\n",
    "    axes[0].set_ylabel('Precision')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Recall plot\n",
    "    axes[1].bar(['Class 0', 'Class 1'], knn_recall_per_class[dataset_index], label='KNN Recall', alpha=0.6)\n",
    "    axes[1].bar(['Class 0', 'Class 1'], knn2_recall_per_class[dataset_index], label='KNN2 Recall', alpha=0.6)\n",
    "    axes[1].set_title(f'Recall for Dataset {datasets[dataset_index]}')\n",
    "    axes[1].set_ylabel('Recall')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "f80f8a4eafcc50a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_index in range(len(datasets)):\n",
    "    plot_precision_recall(dataset_index)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7e0432d0e75f02da",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
